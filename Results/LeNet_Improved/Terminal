C:\Users\stong\Anaconda3\python.exe C:/Users/stong/PycharmProjects/Project_2020_Introvert/main.py

1: LeNet
2: AlexNet
3: VGG-16
4: LeNet_improved

Enter 1-4 to select a model:
4

----Dataset Ratios----
Total dataset size: 70000
Train Set: 68.57%
Validation Set: 17.14%
Test Set: 14.29%

torch.Size([150, 1, 32, 32])
tensor([5, 5, 0, 4, 6, 5, 8, 9, 3, 2, 5, 8, 5, 4, 9, 6, 7, 9, 5, 9, 7, 0, 7, 7,
        5, 3, 5, 3, 3, 7, 3, 1, 0, 3, 5, 1, 0, 4, 5, 4, 8, 6, 0, 6, 9, 5, 1, 1,
        6, 3, 6, 7, 1, 7, 9, 3, 5, 9, 3, 9, 3, 6, 1, 4, 4, 3, 6, 9, 9, 5, 3, 6,
        0, 0, 0, 8, 9, 8, 9, 5, 5, 4, 6, 5, 4, 0, 0, 9, 1, 6, 0, 1, 3, 5, 4, 5,
        0, 6, 3, 4, 7, 9, 6, 2, 1, 7, 9, 7, 6, 9, 5, 9, 8, 5, 8, 4, 7, 0, 1, 6,
        4, 8, 6, 9, 3, 0, 9, 4, 3, 3, 8, 4, 7, 8, 2, 5, 2, 1, 5, 2, 6, 3, 8, 6,
        6, 9, 7, 7, 7, 1])
LeNet_Improved(
  (features): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=400, out_features=120, bias=True)
    (1): ReLU()
    (2): Linear(in_features=120, out_features=84, bias=True)
    (3): ReLU()
    (4): Linear(in_features=84, out_features=10, bias=True)
  )
)

LeNet_Improved activated!

cuda:0
[Epoch 1, 32 / 320 Mini Batches] loss: 2.295
[Epoch 1, 64 / 320 Mini Batches] loss: 2.281
[Epoch 1, 96 / 320 Mini Batches] loss: 2.251
[Epoch 1, 128 / 320 Mini Batches] loss: 2.192
[Epoch 1, 160 / 320 Mini Batches] loss: 2.093
[Epoch 1, 192 / 320 Mini Batches] loss: 1.967
[Epoch 1, 224 / 320 Mini Batches] loss: 1.836
[Epoch 1, 256 / 320 Mini Batches] loss: 1.714
[Epoch 1, 288 / 320 Mini Batches] loss: 1.603
[Epoch 1, 320 / 320 Mini Batches] loss: 1.505
[[4483    3   51    7   22   47  117    2   30    7]
 [   0 5154   73   11    3   33   21   20   30   13]
 [  92   55 4085   64  115   12  160  104   97    2]
 [  19   59  250 4039    8  251   21   58  183   20]
 [  48   31   11    1 4075    4  101   57   40  268]
 [  53   87   73  221  107 3542  148    1   99   32]
 [  72   74  184    0   94   79 4210    4    5    0]
 [  65   75  119    5  136    5    3 4294   67  229]
 [  17  219  134  486   81  140   99  124 3256  107]
 [  60   66   32   67  841   27   10  481  115 3098]]
              precision    recall  f1-score   support

           0      0.913     0.940     0.926      4769
           1      0.885     0.962     0.922      5358
           2      0.815     0.854     0.834      4786
           3      0.824     0.823     0.824      4908
           4      0.743     0.879     0.805      4636
           5      0.856     0.812     0.833      4363
           6      0.861     0.892     0.876      4722
           7      0.835     0.859     0.847      4998
           8      0.830     0.698     0.759      4663
           9      0.820     0.646     0.723      4797

    accuracy                          0.838     48000
   macro avg      0.838     0.836     0.835     48000
weighted avg      0.839     0.838     0.836     48000

[[ 939    0    4    1    2   13   17    1    3    0]
 [   0 1097   20    4    1    0    4    1    7    1]
 [  27    5  882   17   22    0   33   28   18    0]
 [   7    4   56  849    0   46    1   10   33    4]
 [   8    8    1    0  861    0   28    9    6   61]
 [  15   15   10   52   22  714   31    2   20   11]
 [  31    7   40    0   24   16  839    0    1    0]
 [   5   20   47    0   20    0    0  867   16   53]
 [   6   21   24  107   18   32   20   37  687   22]
 [  22   10    6    8  178    7    1   79   13  685]]
              precision    recall  f1-score   support

           0      0.886     0.958     0.921       980
           1      0.924     0.967     0.945      1135
           2      0.809     0.855     0.831      1032
           3      0.818     0.841     0.829      1010
           4      0.750     0.877     0.808       982
           5      0.862     0.800     0.830       892
           6      0.861     0.876     0.869       958
           7      0.838     0.843     0.841      1028
           8      0.854     0.705     0.773       974
           9      0.818     0.679     0.742      1009

    accuracy                          0.842     10000
   macro avg      0.842     0.840     0.839     10000
weighted avg      0.843     0.842     0.840     10000

Epoch: 1 of 10, Train Acc: 83.825, Test Acc: 84.200, Loss: 1.505
[Epoch 2, 32 / 320 Mini Batches] loss: 0.555
[Epoch 2, 64 / 320 Mini Batches] loss: 0.515
[Epoch 2, 96 / 320 Mini Batches] loss: 0.497
[Epoch 2, 128 / 320 Mini Batches] loss: 0.479
[Epoch 2, 160 / 320 Mini Batches] loss: 0.461
[Epoch 2, 192 / 320 Mini Batches] loss: 0.449
[Epoch 2, 224 / 320 Mini Batches] loss: 0.435
[Epoch 2, 256 / 320 Mini Batches] loss: 0.422
[Epoch 2, 288 / 320 Mini Batches] loss: 0.411
[Epoch 2, 320 / 320 Mini Batches] loss: 0.401
[[4613    2   13    3   11   20   56    5   36   10]
 [   2 5199   29   10    8   33   20   19   29    9]
 [  70   30 4205   32   76   16  114   85  120   38]
 [  29   29  136 4106    2  286   11   42  222   45]
 [  18   18    5    0 4244    2   80   21   23  225]
 [  35   44   24   47   27 4039   68    2   54   23]
 [  59   21   30    0   36   67 4499    2    8    0]
 [  35   40   95    7   58    5    2 4489   29  238]
 [  17  107   46   60   29  143   46   24 4035  156]
 [  37   32   23   49  201   34    8  155   64 4194]]
              precision    recall  f1-score   support

           0      0.939     0.967     0.953      4769
           1      0.942     0.970     0.956      5358
           2      0.913     0.879     0.895      4786
           3      0.952     0.837     0.890      4908
           4      0.905     0.915     0.910      4636
           5      0.870     0.926     0.897      4363
           6      0.917     0.953     0.935      4722
           7      0.927     0.898     0.912      4998
           8      0.873     0.865     0.869      4663
           9      0.849     0.874     0.862      4797

    accuracy                          0.909     48000
   macro avg      0.909     0.908     0.908     48000
weighted avg      0.910     0.909     0.909     48000

[[ 968    0    3    0    0    2    4    1    2    0]
 [   0 1113    4    3    1    1    5    0    7    1]
 [  20    2  906    3   15    3   21   26   29    7]
 [   6    2   23  880    0   41    1    7   41    9]
 [   1    3    2    0  904    0   19    3    2   48]
 [  11    4    4    8    5  830   12    2   13    3]
 [  20    4    4    0    8   18  904    0    0    0]
 [   5   11   38    1    5    0    0  907    8   53]
 [   8    5    6   14    7   29    8   10  854   33]
 [  16    5    4    5   42   10    1   24   10  892]]
              precision    recall  f1-score   support

           0      0.918     0.988     0.951       980
           1      0.969     0.981     0.975      1135
           2      0.911     0.878     0.894      1032
           3      0.963     0.871     0.915      1010
           4      0.916     0.921     0.918       982
           5      0.889     0.930     0.909       892
           6      0.927     0.944     0.935       958
           7      0.926     0.882     0.903      1028
           8      0.884     0.877     0.880       974
           9      0.853     0.884     0.868      1009

    accuracy                          0.916     10000
   macro avg      0.915     0.916     0.915     10000
weighted avg      0.916     0.916     0.916     10000

Epoch: 2 of 10, Train Acc: 90.881, Test Acc: 91.580, Loss: 0.401
[Epoch 3, 32 / 320 Mini Batches] loss: 0.306
[Epoch 3, 64 / 320 Mini Batches] loss: 0.291
[Epoch 3, 96 / 320 Mini Batches] loss: 0.292
[Epoch 3, 128 / 320 Mini Batches] loss: 0.288
[Epoch 3, 160 / 320 Mini Batches] loss: 0.282
[Epoch 3, 192 / 320 Mini Batches] loss: 0.281
[Epoch 3, 224 / 320 Mini Batches] loss: 0.275
[Epoch 3, 256 / 320 Mini Batches] loss: 0.271
[Epoch 3, 288 / 320 Mini Batches] loss: 0.266
[Epoch 3, 320 / 320 Mini Batches] loss: 0.263
[[4648    1    7    3   14    9   35    8   39    5]
 [   3 5203   28   18   13   18   15   17   40    3]
 [  54   25 4280   58   71    7   53   82  130   26]
 [  16   17   65 4500    2  102    4   32  153   17]
 [  14   18    5    2 4397    1   35   21   22  121]
 [  30   28   14   74   20 4035   39    4  100   19]
 [  50   16   10    0   61   46 4510    1   28    0]
 [  20   22   82   22   56    3    1 4659   29  104]
 [  18   60   19   70   19   48   18   17 4318   76]
 [  31   22   20   63  215   19    2  175   79 4171]]
              precision    recall  f1-score   support

           0      0.952     0.975     0.963      4769
           1      0.961     0.971     0.966      5358
           2      0.945     0.894     0.919      4786
           3      0.936     0.917     0.926      4908
           4      0.903     0.948     0.925      4636
           5      0.941     0.925     0.933      4363
           6      0.957     0.955     0.956      4722
           7      0.929     0.932     0.930      4998
           8      0.874     0.926     0.899      4663
           9      0.918     0.870     0.893      4797

    accuracy                          0.932     48000
   macro avg      0.932     0.931     0.931     48000
weighted avg      0.932     0.932     0.932     48000

[[ 969    0    3    0    0    1    3    1    3    0]
 [   0 1113    4    2    1    0    5    0    9    1]
 [  17    0  924    9   12    1    7   21   36    5]
 [   3    1   10  948    0   10    0    5   29    4]
 [   1    2    3    0  933    0    8    3    2   30]
 [  11    3    3   13    1  831    5    2   21    2]
 [  21    4    3    0   13   10  906    0    1    0]
 [   3    5   32    5    3    0    0  946    9   25]
 [   7    1    2   16    4   10    3   13  907   11]
 [  14    5    5    5   40    7    0   29   15  889]]
              precision    recall  f1-score   support

           0      0.926     0.989     0.957       980
           1      0.981     0.981     0.981      1135
           2      0.934     0.895     0.914      1032
           3      0.950     0.939     0.944      1010
           4      0.927     0.950     0.938       982
           5      0.955     0.932     0.943       892
           6      0.967     0.946     0.956       958
           7      0.927     0.920     0.924      1028
           8      0.879     0.931     0.904       974
           9      0.919     0.881     0.900      1009

    accuracy                          0.937     10000
   macro avg      0.937     0.936     0.936     10000
weighted avg      0.937     0.937     0.937     10000

Epoch: 3 of 10, Train Acc: 93.169, Test Acc: 93.660, Loss: 0.263
[Epoch 4, 32 / 320 Mini Batches] loss: 0.226
[Epoch 4, 64 / 320 Mini Batches] loss: 0.218
[Epoch 4, 96 / 320 Mini Batches] loss: 0.223
[Epoch 4, 128 / 320 Mini Batches] loss: 0.222
[Epoch 4, 160 / 320 Mini Batches] loss: 0.218
[Epoch 4, 192 / 320 Mini Batches] loss: 0.217
[Epoch 4, 224 / 320 Mini Batches] loss: 0.213
[Epoch 4, 256 / 320 Mini Batches] loss: 0.211
[Epoch 4, 288 / 320 Mini Batches] loss: 0.209
[Epoch 4, 320 / 320 Mini Batches] loss: 0.206
[[4624    3   25    4    7   19   39   11   30    7]
 [   3 5229   32   18   13    8   15   16   21    3]
 [  21   21 4500   44   31    5   22   67   53   22]
 [   9   15   89 4590    0   71    5   29   75   25]
 [   9   19   11    2 4371    1   40   14   10  159]
 [  11   17   17   60    5 4137   28    4   50   34]
 [  34   11   16    0   26   40 4576    0   19    0]
 [  13   13   80   17   39    4    1 4686   17  128]
 [  14   49   43   86   10   47   19   13 4293   89]
 [  19   18   21   61   95   15    2  106   48 4412]]
              precision    recall  f1-score   support

           0      0.972     0.970     0.971      4769
           1      0.969     0.976     0.973      5358
           2      0.931     0.940     0.936      4786
           3      0.940     0.935     0.938      4908
           4      0.951     0.943     0.947      4636
           5      0.952     0.948     0.950      4363
           6      0.964     0.969     0.967      4722
           7      0.947     0.938     0.942      4998
           8      0.930     0.921     0.925      4663
           9      0.904     0.920     0.912      4797

    accuracy                          0.946     48000
   macro avg      0.946     0.946     0.946     48000
weighted avg      0.946     0.946     0.946     48000

[[ 967    0    5    0    0    1    4    1    2    0]
 [   0 1121    4    2    1    0    5    0    2    0]
 [  10    0  972    7    5    1    6   16   10    5]
 [   1    0   14  962    0    9    0    5   15    4]
 [   1    2    3    0  924    0    8    2    2   40]
 [   5    2    4   12    0  849    4    2   11    3]
 [  12    2    6    0    7    9  921    0    1    0]
 [   3    4   31    5    2    0    0  950    6   27]
 [   6    1    6   21    4   10    2   10  898   16]
 [  10    6    3    7   18    7    0   14    6  938]]
              precision    recall  f1-score   support

           0      0.953     0.987     0.969       980
           1      0.985     0.988     0.986      1135
           2      0.927     0.942     0.935      1032
           3      0.947     0.952     0.950      1010
           4      0.961     0.941     0.951       982
           5      0.958     0.952     0.955       892
           6      0.969     0.961     0.965       958
           7      0.950     0.924     0.937      1028
           8      0.942     0.922     0.932       974
           9      0.908     0.930     0.919      1009

    accuracy                          0.950     10000
   macro avg      0.950     0.950     0.950     10000
weighted avg      0.950     0.950     0.950     10000

Epoch: 4 of 10, Train Acc: 94.621, Test Acc: 95.020, Loss: 0.206
[Epoch 5, 32 / 320 Mini Batches] loss: 0.165
[Epoch 5, 64 / 320 Mini Batches] loss: 0.180
[Epoch 5, 96 / 320 Mini Batches] loss: 0.182
[Epoch 5, 128 / 320 Mini Batches] loss: 0.180
[Epoch 5, 160 / 320 Mini Batches] loss: 0.178
[Epoch 5, 192 / 320 Mini Batches] loss: 0.178
[Epoch 5, 224 / 320 Mini Batches] loss: 0.175
[Epoch 5, 256 / 320 Mini Batches] loss: 0.173
[Epoch 5, 288 / 320 Mini Batches] loss: 0.171
[Epoch 5, 320 / 320 Mini Batches] loss: 0.170
[[4701    3   16    1    4    4   22    5   12    1]
 [   3 5260   39    8   12    2    9    9   15    1]
 [  31   20 4629   13   24    1    6   31   24    7]
 [  16   17  163 4498    1   71    4   23  100   15]
 [  17   29   12    1 4443    1   30   18   14   71]
 [  25   20   21   28    3 4160   32    5   50   19]
 [  52   15   12    0   22   26 4579    0   16    0]
 [  25   24  125   12   33    2    1 4709   19   48]
 [  32   58   71   40    9   24   18    9 4377   25]
 [  28   25   19   54  129   18    2  128   73 4321]]
              precision    recall  f1-score   support

           0      0.954     0.986     0.969      4769
           1      0.961     0.982     0.971      5358
           2      0.906     0.967     0.936      4786
           3      0.966     0.916     0.941      4908
           4      0.949     0.958     0.954      4636
           5      0.965     0.953     0.959      4363
           6      0.974     0.970     0.972      4722
           7      0.954     0.942     0.948      4998
           8      0.931     0.939     0.935      4663
           9      0.959     0.901     0.929      4797

    accuracy                          0.952     48000
   macro avg      0.952     0.951     0.951     48000
weighted avg      0.952     0.952     0.952     48000

[[ 975    0    2    0    0    0    1    1    1    0]
 [   0 1125    4    2    0    0    4    0    0    0]
 [  12    0  997    3    3    1    1    8    5    2]
 [   3    0   24  942    0   10    0    7   22    2]
 [   2    2    4    0  948    0    7    2    2   15]
 [  11    2    4    6    0  852    2    1   12    2]
 [  18    3    6    0    6    5  919    0    1    0]
 [   3    5   45    4    2    0    0  955    5    9]
 [  10    1    8   10    2    7    2    8  922    4]
 [  11    8    3    5   22    6    0   17   13  924]]
              precision    recall  f1-score   support

           0      0.933     0.995     0.963       980
           1      0.982     0.991     0.986      1135
           2      0.909     0.966     0.937      1032
           3      0.969     0.933     0.951      1010
           4      0.964     0.965     0.965       982
           5      0.967     0.955     0.961       892
           6      0.982     0.959     0.970       958
           7      0.956     0.929     0.942      1028
           8      0.938     0.947     0.942       974
           9      0.965     0.916     0.940      1009

    accuracy                          0.956     10000
   macro avg      0.956     0.956     0.956     10000
weighted avg      0.957     0.956     0.956     10000

Epoch: 5 of 10, Train Acc: 95.160, Test Acc: 95.590, Loss: 0.170
[Epoch 6, 32 / 320 Mini Batches] loss: 0.173
[Epoch 6, 64 / 320 Mini Batches] loss: 0.162
[Epoch 6, 96 / 320 Mini Batches] loss: 0.155
[Epoch 6, 128 / 320 Mini Batches] loss: 0.152
[Epoch 6, 160 / 320 Mini Batches] loss: 0.150
[Epoch 6, 192 / 320 Mini Batches] loss: 0.148
[Epoch 6, 224 / 320 Mini Batches] loss: 0.148
[Epoch 6, 256 / 320 Mini Batches] loss: 0.146
[Epoch 6, 288 / 320 Mini Batches] loss: 0.146
[Epoch 6, 320 / 320 Mini Batches] loss: 0.144
[[4679    2   10    2    5    7   22    9   19   14]
 [   3 5258   30   16   14    1    6    9   18    3]
 [  26   28 4507   47   23    1    4   78   56   16]
 [  11    9   44 4671    0   39    2   28   74   30]
 [  10   18    6    1 4436    0   20   16    8  121]
 [  14   10    6   39    5 4143   26    3   62   55]
 [  34   16    3    0   33   22 4587    0   27    0]
 [  11   11   42   16   27    1    0 4778   17   95]
 [  16   36   17   57    9   15   12   10 4430   61]
 [  13   13    2   43   46    8    2   63   33 4574]]
              precision    recall  f1-score   support

           0      0.971     0.981     0.976      4769
           1      0.974     0.981     0.977      5358
           2      0.966     0.942     0.954      4786
           3      0.955     0.952     0.953      4908
           4      0.965     0.957     0.961      4636
           5      0.978     0.950     0.963      4363
           6      0.980     0.971     0.976      4722
           7      0.957     0.956     0.956      4998
           8      0.934     0.950     0.942      4663
           9      0.921     0.954     0.937      4797

    accuracy                          0.960     48000
   macro avg      0.960     0.959     0.960     48000
weighted avg      0.960     0.960     0.960     48000

[[ 973    0    2    0    0    0    1    1    3    0]
 [   0 1123    3    2    1    0    4    0    2    0]
 [  10    0  982    7    3    0    2   15   11    2]
 [   1    0    4  978    0    6    0    5   12    4]
 [   1    2    3    0  936    0    6    2    2   30]
 [   5    2    1    8    0  851    4    1   11    9]
 [  11    3    3    0    8    4  926    0    3    0]
 [   2    4   20    5    1    0    0  968    4   24]
 [   7    0    3   13    2    3    0    8  931    7]
 [   8    4    0    6    7    4    0   10    3  967]]
              precision    recall  f1-score   support

           0      0.956     0.993     0.974       980
           1      0.987     0.989     0.988      1135
           2      0.962     0.952     0.957      1032
           3      0.960     0.968     0.964      1010
           4      0.977     0.953     0.965       982
           5      0.980     0.954     0.967       892
           6      0.982     0.967     0.974       958
           7      0.958     0.942     0.950      1028
           8      0.948     0.956     0.952       974
           9      0.927     0.958     0.942      1009

    accuracy                          0.964     10000
   macro avg      0.964     0.963     0.963     10000
weighted avg      0.964     0.964     0.964     10000

Epoch: 6 of 10, Train Acc: 95.965, Test Acc: 96.350, Loss: 0.144
[Epoch 7, 32 / 320 Mini Batches] loss: 0.143
[Epoch 7, 64 / 320 Mini Batches] loss: 0.135
[Epoch 7, 96 / 320 Mini Batches] loss: 0.134
[Epoch 7, 128 / 320 Mini Batches] loss: 0.133
[Epoch 7, 160 / 320 Mini Batches] loss: 0.132
[Epoch 7, 192 / 320 Mini Batches] loss: 0.131
[Epoch 7, 224 / 320 Mini Batches] loss: 0.130
[Epoch 7, 256 / 320 Mini Batches] loss: 0.128
[Epoch 7, 288 / 320 Mini Batches] loss: 0.127
[Epoch 7, 320 / 320 Mini Batches] loss: 0.126
[[4657    1   16    2    4   21   36    6   18    8]
 [   2 5271   29   14   14    1    7    5   13    2]
 [  16   31 4592   33   12    2    6   46   44    4]
 [   8    9   52 4651    0   68    3   25   77   15]
 [   8   21    7    2 4478    0   26   14   11   69]
 [  12    9    5   24    2 4248   20    4   26   13]
 [  17   10    3    0   13   30 4630    0   19    0]
 [  11   14   49   13   24    4    0 4821   20   42]
 [   9   37   20   45    8   32   17    8 4466   21]
 [  17   16    5   47   64   22    2   83   45 4496]]
              precision    recall  f1-score   support

           0      0.979     0.977     0.978      4769
           1      0.973     0.984     0.978      5358
           2      0.961     0.959     0.960      4786
           3      0.963     0.948     0.955      4908
           4      0.969     0.966     0.968      4636
           5      0.959     0.974     0.966      4363
           6      0.975     0.981     0.978      4722
           7      0.962     0.965     0.963      4998
           8      0.942     0.958     0.950      4663
           9      0.963     0.937     0.950      4797

    accuracy                          0.965     48000
   macro avg      0.965     0.965     0.965     48000
weighted avg      0.965     0.965     0.965     48000

[[ 968    0    3    0    0    0    5    1    3    0]
 [   0 1123    3    2    0    1    6    0    0    0]
 [   7    3  993    6    3    0    2   10    8    0]
 [   1    0    4  976    0    9    0    5   13    2]
 [   1    3    3    0  950    0    8    1    2   14]
 [   2    0    1    4    0  873    4    1    7    0]
 [   6    3    3    0    4    6  935    0    1    0]
 [   2    6   21    4    2    0    0  976    4   13]
 [   6    0    3    9    2    4    2    7  937    4]
 [   9    8    0    7   11    6    0   11    6  951]]
              precision    recall  f1-score   support

           0      0.966     0.988     0.977       980
           1      0.980     0.989     0.985      1135
           2      0.960     0.962     0.961      1032
           3      0.968     0.966     0.967      1010
           4      0.977     0.967     0.972       982
           5      0.971     0.979     0.975       892
           6      0.972     0.976     0.974       958
           7      0.964     0.949     0.957      1028
           8      0.955     0.962     0.959       974
           9      0.966     0.943     0.954      1009

    accuracy                          0.968     10000
   macro avg      0.968     0.968     0.968     10000
weighted avg      0.968     0.968     0.968     10000

Epoch: 7 of 10, Train Acc: 96.479, Test Acc: 96.820, Loss: 0.126
[Epoch 8, 32 / 320 Mini Batches] loss: 0.124
[Epoch 8, 64 / 320 Mini Batches] loss: 0.120
[Epoch 8, 96 / 320 Mini Batches] loss: 0.115
[Epoch 8, 128 / 320 Mini Batches] loss: 0.115
[Epoch 8, 160 / 320 Mini Batches] loss: 0.114
[Epoch 8, 192 / 320 Mini Batches] loss: 0.116
[Epoch 8, 224 / 320 Mini Batches] loss: 0.114
[Epoch 8, 256 / 320 Mini Batches] loss: 0.114
[Epoch 8, 288 / 320 Mini Batches] loss: 0.114
[Epoch 8, 320 / 320 Mini Batches] loss: 0.112
[[4693    1    5    1    2    8   39    1   11    8]
 [   2 5265   31    9   15    1   16    6   11    2]
 [  25   23 4625   22   11    2    9   32   33    4]
 [  11    7   60 4650    1   61    3   19   76   20]
 [   8   12    6    1 4507    0   32   10    7   53]
 [  12    8    3   14    2 4238   42    3   23   18]
 [  19    5    1    0   12   13 4664    0    8    0]
 [  12   11   54   10   28    4    1 4819   17   42]
 [  19   26   22   28   10   21   38    6 4467   26]
 [  17   13    3   38   79   20    2   57   34 4534]]
              precision    recall  f1-score   support

           0      0.974     0.984     0.979      4769
           1      0.980     0.983     0.981      5358
           2      0.962     0.966     0.964      4786
           3      0.974     0.947     0.961      4908
           4      0.966     0.972     0.969      4636
           5      0.970     0.971     0.971      4363
           6      0.962     0.988     0.975      4722
           7      0.973     0.964     0.969      4998
           8      0.953     0.958     0.956      4663
           9      0.963     0.945     0.954      4797

    accuracy                          0.968     48000
   macro avg      0.968     0.968     0.968     48000
weighted avg      0.968     0.968     0.968     48000

[[ 971    0    1    0    0    0    5    1    2    0]
 [   0 1123    3    2    0    1    6    0    0    0]
 [   9    3 1001    3    2    0    2    7    5    0]
 [   1    0    4  976    0   10    0    5   12    2]
 [   2    2    3    0  958    0    8    1    2    6]
 [   4    0    0    4    0  873    4    1    5    1]
 [   5    3    0    0    3    1  945    0    1    0]
 [   2    5   24    4    3    0    0  974    3   13]
 [   7    0    3    7    3    3    5    6  936    4]
 [   8    5    1    6   12    5    0    7    3  962]]
              precision    recall  f1-score   support

           0      0.962     0.991     0.976       980
           1      0.984     0.989     0.987      1135
           2      0.963     0.970     0.966      1032
           3      0.974     0.966     0.970      1010
           4      0.977     0.976     0.976       982
           5      0.978     0.979     0.978       892
           6      0.969     0.986     0.978       958
           7      0.972     0.947     0.960      1028
           8      0.966     0.961     0.963       974
           9      0.974     0.953     0.963      1009

    accuracy                          0.972     10000
   macro avg      0.972     0.972     0.972     10000
weighted avg      0.972     0.972     0.972     10000

Epoch: 8 of 10, Train Acc: 96.796, Test Acc: 97.190, Loss: 0.112
[Epoch 9, 32 / 320 Mini Batches] loss: 0.118
[Epoch 9, 64 / 320 Mini Batches] loss: 0.108
[Epoch 9, 96 / 320 Mini Batches] loss: 0.106
[Epoch 9, 128 / 320 Mini Batches] loss: 0.106
[Epoch 9, 160 / 320 Mini Batches] loss: 0.107
[Epoch 9, 192 / 320 Mini Batches] loss: 0.104
[Epoch 9, 224 / 320 Mini Batches] loss: 0.104
[Epoch 9, 256 / 320 Mini Batches] loss: 0.104
[Epoch 9, 288 / 320 Mini Batches] loss: 0.103
[Epoch 9, 320 / 320 Mini Batches] loss: 0.102
[[4691    1    9    2    3   12   26    4   10   11]
 [   2 5259   36   16   15    1    7   10    9    3]
 [  14   10 4658   28    7    1    2   38   24    4]
 [   6    2   46 4724    0   40    3   19   49   19]
 [   8   12    7    2 4467    0   21   15    6   98]
 [  10    4    5   25    2 4256   19    3   20   19]
 [  19    6    3    0   12   20 4647    0   15    0]
 [   6    7   46   10   15    2    0 4861    9   42]
 [  11   26   28   54    7   25   16    8 4447   41]
 [  14    5    1   45   29   12    2   48   17 4624]]
              precision    recall  f1-score   support

           0      0.981     0.984     0.982      4769
           1      0.986     0.982     0.984      5358
           2      0.963     0.973     0.968      4786
           3      0.963     0.963     0.963      4908
           4      0.980     0.964     0.972      4636
           5      0.974     0.975     0.975      4363
           6      0.980     0.984     0.982      4722
           7      0.971     0.973     0.972      4998
           8      0.965     0.954     0.960      4663
           9      0.951     0.964     0.958      4797

    accuracy                          0.972     48000
   macro avg      0.971     0.971     0.971     48000
weighted avg      0.972     0.972     0.972     48000

[[ 972    0    2    0    0    0    2    1    3    0]
 [   0 1123    3    2    0    1    5    0    1    0]
 [   9    1 1003    5    2    0    1    9    2    0]
 [   1    0    4  982    0    7    0    5    9    2]
 [   3    1    3    0  945    0    6    2    2   20]
 [   3    0    1    5    0  871    4    1    6    1]
 [   6    3    3    0    3    5  937    0    1    0]
 [   2    1   20    5    1    0    0  985    3   11]
 [   7    0    4   12    2    2    2    7  932    6]
 [   7    4    1    6    6    4    0    7    1  973]]
              precision    recall  f1-score   support

           0      0.962     0.992     0.977       980
           1      0.991     0.989     0.990      1135
           2      0.961     0.972     0.966      1032
           3      0.966     0.972     0.969      1010
           4      0.985     0.962     0.974       982
           5      0.979     0.976     0.978       892
           6      0.979     0.978     0.979       958
           7      0.969     0.958     0.963      1028
           8      0.971     0.957     0.964       974
           9      0.961     0.964     0.962      1009

    accuracy                          0.972     10000
   macro avg      0.972     0.972     0.972     10000
weighted avg      0.972     0.972     0.972     10000

Epoch: 9 of 10, Train Acc: 97.154, Test Acc: 97.230, Loss: 0.102
[Epoch 10, 32 / 320 Mini Batches] loss: 0.097
[Epoch 10, 64 / 320 Mini Batches] loss: 0.094
[Epoch 10, 96 / 320 Mini Batches] loss: 0.093
[Epoch 10, 128 / 320 Mini Batches] loss: 0.092
[Epoch 10, 160 / 320 Mini Batches] loss: 0.093
[Epoch 10, 192 / 320 Mini Batches] loss: 0.094
[Epoch 10, 224 / 320 Mini Batches] loss: 0.093
[Epoch 10, 256 / 320 Mini Batches] loss: 0.095
[Epoch 10, 288 / 320 Mini Batches] loss: 0.095
[Epoch 10, 320 / 320 Mini Batches] loss: 0.094
[[4682    3   12    1    3   14   30    3    8   13]
 [   2 5290   26   11   13    0    4    7    4    1]
 [  11   23 4654   29    8    0    3   34   21    3]
 [   6    3   38 4737    0   40    3   17   43   21]
 [   3   15    8    1 4499    0   17    9    5   79]
 [   7    7    5   20    3 4262   18    3   18   20]
 [  14    7    1    0   13   23 4651    0   13    0]
 [   4    9   38   11   18    2    0 4860   11   45]
 [  10   35   24   49    8   22   18    8 4442   47]
 [  11    5    1   41   29   12    2   33   11 4652]]
              precision    recall  f1-score   support

           0      0.986     0.982     0.984      4769
           1      0.980     0.987     0.984      5358
           2      0.968     0.972     0.970      4786
           3      0.967     0.965     0.966      4908
           4      0.979     0.970     0.975      4636
           5      0.974     0.977     0.976      4363
           6      0.980     0.985     0.982      4722
           7      0.977     0.972     0.975      4998
           8      0.971     0.953     0.962      4663
           9      0.953     0.970     0.961      4797

    accuracy                          0.974     48000
   macro avg      0.974     0.973     0.973     48000
weighted avg      0.974     0.974     0.974     48000

[[ 972    0    2    0    0    0    3    1    2    0]
 [   0 1127    3    2    0    1    2    0    0    0]
 [   4    3 1008    4    2    0    1    8    2    0]
 [   1    0    3  984    0    8    0    5    7    2]
 [   1    1    3    0  958    0    4    1    2   12]
 [   1    0    0    5    0  876    4    1    4    1]
 [   6    3    1    0    3    5  939    0    1    0]
 [   2    3   18    3    1    0    0  987    2   12]
 [   6    0    3   11    4    2    2    7  932    7]
 [   5    5    1    6    5    4    0    7    0  976]]
              precision    recall  f1-score   support

           0      0.974     0.992     0.983       980
           1      0.987     0.993     0.990      1135
           2      0.967     0.977     0.972      1032
           3      0.969     0.974     0.972      1010
           4      0.985     0.976     0.980       982
           5      0.978     0.982     0.980       892
           6      0.983     0.980     0.982       958
           7      0.971     0.960     0.965      1028
           8      0.979     0.957     0.968       974
           9      0.966     0.967     0.967      1009

    accuracy                          0.976     10000
   macro avg      0.976     0.976     0.976     10000
weighted avg      0.976     0.976     0.976     10000

Epoch: 10 of 10, Train Acc: 97.352, Test Acc: 97.590, Loss: 0.094
6.24 minutes

Process finished with exit code 0
